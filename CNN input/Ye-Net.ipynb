{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z50OYro9ATCC"
      },
      "source": [
        "# Ye-Net CNN Input TPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJUl7AD6ATCE"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ZIP_PATH = \"/content/drive/MyDrive/Dissertation/BOSSbase.zip\"\n",
        "EXTRACT_TO = \"/content/data\"\n",
        "\n",
        "import os, zipfile\n",
        "os.makedirs(EXTRACT_TO, exist_ok=True)\n",
        "\n",
        "if not os.path.exists(os.path.join(EXTRACT_TO, \"BOSSbase_256\")):\n",
        "    with zipfile.ZipFile(ZIP_PATH, 'r') as z:\n",
        "        z.extractall(EXTRACT_TO)\n",
        "    print(\" Unzipped to\", EXTRACT_TO)\n",
        "else:\n",
        "    print(\" Already extracted:\", EXTRACT_TO)\n"
      ],
      "metadata": {
        "id": "TxxOeNKmBHr-",
        "outputId": "566e8a90-d687-4214-ad9e-e67b32601834",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/Dissertation/BOSSbase.zip'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1833339841.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEXTRACT_TO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"BOSSbase_256\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZIP_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEXTRACT_TO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" Unzipped to\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEXTRACT_TO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/zipfile/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1350\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Dissertation/BOSSbase.zip'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkYLr7xzATCE"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yB0LUKf5ATCE"
      },
      "outputs": [],
      "source": [
        "from scipy import misc, ndimage, signal\n",
        "from sklearn.model_selection  import train_test_split\n",
        "import numpy\n",
        "import numpy as np\n",
        "import random\n",
        "import ntpath\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as colors\n",
        "from keras import optimizers\n",
        "from keras import regularizers\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from keras import backend as K\n",
        "from time import time\n",
        "import time as tm\n",
        "import datetime\n",
        "from operator import itemgetter\n",
        "import glob\n",
        "from skimage.util.shape import view_as_blocks\n",
        "from keras.utils import np_utils\n",
        "from keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aN07vFVOATCF"
      },
      "source": [
        "## 30 SRM filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PemRslyWATCF"
      },
      "outputs": [],
      "source": [
        "################################################## 30 SRM FILTERS\n",
        "srm_weights = np.load('SRM_Kernels.npy')\n",
        "biasSRM=numpy.ones(30)\n",
        "print (srm_weights.shape)\n",
        "################################################## TLU ACTIVATION FUNCTION\n",
        "T3 = 3;\n",
        "def Tanh3(x):\n",
        "    tanh3 = K.tanh(x)*T3\n",
        "    return tanh3\n",
        "##################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOUZkzJOATCF"
      },
      "source": [
        "## TPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOFB-GrNATCF"
      },
      "outputs": [],
      "source": [
        "#https://www.tensorflow.org/guide/tpu\n",
        "#https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/tpu.ipynb\n",
        "#https://colab.research.google.com/notebooks/tpu.ipynb#scrollTo=_pQCOmISAQBu\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.TPUStrategy(tpu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBfMWme3ATCF"
      },
      "source": [
        "## Ye-Net architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9J4CVYUATCG"
      },
      "outputs": [],
      "source": [
        "def Ye_Net(img_size=256):\n",
        "    #tf.keras.backend.clear_session()\n",
        "\n",
        "    #Inputs\n",
        "    inputs = tf.keras.Input(shape=(img_size,img_size,1), name=\"input_1\")\n",
        "    print(inputs.shape)\n",
        "\n",
        "    #Block 1\n",
        "    layers = tf.keras.layers.Conv2D(30, (5,5), weights=[srm_weights,biasSRM], strides=(1,1), trainable=False, activation=Tanh3, use_bias=True)(inputs)\n",
        "\n",
        "    print(layers.shape)\n",
        "\n",
        "    #Block 2\n",
        "\n",
        "    layers = tf.keras.layers.Conv2D(30, (3,3), strides=(1,1), kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
        "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
        "    layers = tf.keras.layers.Concatenate()([layers, layers, layers])\n",
        "    print(layers.shape)\n",
        "\n",
        "    #Block 3\n",
        "    layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
        "    layers = tf.keras.layers.Conv2D(30, (3,3), strides=(1,1), kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
        "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
        "    print(layers.shape)\n",
        "\n",
        "    #Block 4\n",
        "    layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
        "    layers = tf.keras.layers.Conv2D(30, (3,3), strides=(1,1), kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
        "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
        "    layers = tf.keras.layers.AveragePooling2D((2,2), strides= (2,2))(layers)\n",
        "    print(layers.shape)\n",
        "\n",
        "    #Block 5\n",
        "    layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
        "    layers = tf.keras.layers.Conv2D(32, (5,5), strides=(1,1), kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
        "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
        "    print(layers.shape)\n",
        "\n",
        "    #Block 6\n",
        "    layers = tf.keras.layers.Concatenate()([layers, layers, layers])\n",
        "    layers = tf.keras.layers.GlobalAveragePooling2D(data_format=\"channels_last\")(layers)\n",
        "    layers = tf.keras.layers.Dense(128,kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = tf.keras.layers.Dense(64,kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = tf.keras.layers.Dense(32,kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    predictions = tf.keras.layers.Dense(2,kernel_initializer='glorot_normal', activation=\"softmax\", name=\"output_1\",kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    print(predictions.shape)\n",
        "\n",
        "    #Model generation\n",
        "    model = tf.keras.Model(inputs = inputs, outputs=predictions)\n",
        "    #Optimizer\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.005, momentum=0.95)#lrate\n",
        "    #Compilator\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    print (\"Ye-net model 2 generated\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYrSAFdzATCG"
      },
      "source": [
        "## Defining different functions to work with the architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDUhPnAAATCG"
      },
      "outputs": [],
      "source": [
        "\n",
        "def Final_Results_Valid(PATH_trained_models):\n",
        "    global AccValid\n",
        "    global LossValid\n",
        "    AccValid = []\n",
        "    LossValid = []\n",
        "    B_accuracy = 0 #B --> Best\n",
        "    for filename in sorted(os.listdir(PATH_trained_models)):\n",
        "        if filename != ('train') and filename != ('validation'):\n",
        "            print(filename)\n",
        "            with tpu_strategy.scope(): # creating the model in the TPUStrategy scope means we will train the model on the TPU\n",
        "                 _model = Ye_Net()\n",
        "            _model.load_weights(PATH_trained_models+'/'+filename)\n",
        "            loss,accuracy = _model.evaluate(X_valid, y_valid, verbose=0)\n",
        "            print(f'Loss={loss:.4f} y Accuracy={accuracy:0.4f}'+'\\n')\n",
        "\n",
        "            BandAccValid  = accuracy\n",
        "            BandLossValid = loss\n",
        "            AccValid.append(BandAccValid)\n",
        "            LossValid.append(BandLossValid)\n",
        "\n",
        "            if accuracy > B_accuracy:\n",
        "                B_accuracy = accuracy\n",
        "                B_loss = loss\n",
        "                B_name = filename\n",
        "\n",
        "    print(\"\\n\\nBest\")\n",
        "    print(B_name)\n",
        "    print(f'Loss={B_loss:.4f} y Accuracy={B_accuracy:0.4f}'+'\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQZFSkhuATCH"
      },
      "outputs": [],
      "source": [
        "def Final_Results_Train(PATH_trained_models):\n",
        "    global AccTrain\n",
        "    global LossTrain\n",
        "    AccTrain = []\n",
        "    LossTrain = []\n",
        "    B_accuracy = 0 #B --> Best\n",
        "    for filename in sorted(os.listdir(PATH_trained_models)):\n",
        "        if filename != ('train') and filename != ('validation'):\n",
        "            print(filename)\n",
        "            with tpu_strategy.scope(): # creating the model in the TPUStrategy scope means we will train the model on the TPU\n",
        "                 _model = Ye_Net()\n",
        "            _model.load_weights(PATH_trained_models+'/'+filename)\n",
        "            loss,accuracy = _model.evaluate(X_train, y_train, verbose=0)\n",
        "            print(f'Loss={loss:.4f} y Accuracy={accuracy:0.4f}'+'\\n')\n",
        "\n",
        "            BandAccTrain  = accuracy\n",
        "            BandLossTrain = loss\n",
        "            AccTrain.append(BandAccTrain)\n",
        "            LossTrain.append(BandLossTrain)\n",
        "\n",
        "            if accuracy > B_accuracy:\n",
        "                B_accuracy = accuracy\n",
        "                B_loss = loss\n",
        "                B_name = filename\n",
        "\n",
        "    print(\"\\n\\nBest\")\n",
        "    print(B_name)\n",
        "    print(f'Loss={B_loss:.4f} y Accuracy={B_accuracy:0.4f}'+'\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bB1ojyj4ATCH"
      },
      "outputs": [],
      "source": [
        "def Final_Results_Test(PATH_trained_models):\n",
        "    global AccTest\n",
        "    global LossTest\n",
        "    AccTest = []\n",
        "    LossTest= []\n",
        "    B_accuracy = 0 #B --> Best\n",
        "    for filename in sorted(os.listdir(PATH_trained_models)):\n",
        "        if filename != ('train') and filename != ('validation'):\n",
        "            print(filename)\n",
        "            with tpu_strategy.scope(): # creating the model in the TPUStrategy scope means we will train the model on the TPU\n",
        "                 _model = Ye_Net()\n",
        "            _model.load_weights(PATH_trained_models+'/'+filename)\n",
        "            loss,accuracy = _model.evaluate(X_test, y_test, verbose=0)\n",
        "            print(f'Loss={loss:.4f} y Accuracy={accuracy:0.4f}'+'\\n')\n",
        "\n",
        "            BandAccTest  = accuracy\n",
        "            BandLossTest = loss\n",
        "            AccTest.append(BandAccTest)\n",
        "            LossTest.append(BandLossTest)\n",
        "\n",
        "            if accuracy > B_accuracy:\n",
        "                B_accuracy = accuracy\n",
        "                B_loss = loss\n",
        "                B_name = filename\n",
        "\n",
        "    print(\"\\n\\nBest\")\n",
        "    print(B_name)\n",
        "    print(f'Loss={B_loss:.4f} y Accuracy={B_accuracy:0.4f}'+'\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5RKgiHJATCH"
      },
      "outputs": [],
      "source": [
        "def graphics(AccTest, AccTrain, AccValid, LossTest, LossTrain, LossValid, model_name, path_img_base):\n",
        "    if not os.path.exists(path_img_base+\"/\"+model_name):\n",
        "       os.makedirs(path_img_base+\"/\"+model_name)\n",
        "\n",
        "    with tpu_strategy.scope(): # creating the model in the TPUStrategy scope means we will train the model on the TPU\n",
        "        model = Ye_Net()\n",
        "\n",
        "    lossTEST,accuracyTEST   = model.evaluate(X_test, y_test,verbose=None)\n",
        "    lossTRAIN,accuracyTRAIN = model.evaluate(X_train, y_train,verbose=None)\n",
        "    lossVALID,accuracyVALID = model.evaluate(X_valid, y_valid,verbose=None)\n",
        "\n",
        "    with plt.style.context('seaborn-white'):\n",
        "        plt.figure(figsize=(10, 10))\n",
        "        plt.plot(np.concatenate([np.array([accuracyTRAIN]),np.array(AccTrain)],axis=0))\n",
        "        plt.plot(np.concatenate([np.array([accuracyVALID]),np.array(AccValid)],axis=0))\n",
        "        plt.plot(np.concatenate([np.array([accuracyTEST]),np.array(AccTest)],axis=0)) #Test\n",
        "        plt.title('Accuracy Vs Epoch')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.legend(['Train', 'Validation', 'Test'], loc='upper left')\n",
        "        plt.grid('on')\n",
        "        plt.savefig(path_img_base+'/'+model_name+'/Accuracy_Ye_Net_'+model_name+'.eps', format='eps')\n",
        "        plt.savefig(path_img_base+'/'+model_name+'/Accuracy_Ye_Net_'+model_name+'.svg', format='svg')\n",
        "        plt.savefig(path_img_base+'/'+model_name+'/Accuracy_Ye_Net_'+model_name+'.pdf', format='pdf')\n",
        "        plt.show()\n",
        "\n",
        "        plt.figure(figsize=(10, 10))\n",
        "        plt.plot(np.concatenate([np.array([lossTRAIN]),np.array(LossTrain)],axis=0))\n",
        "        plt.plot(np.concatenate([np.array([lossVALID]),np.array(LossValid)],axis=0))\n",
        "        plt.plot(np.concatenate([np.array([lossTEST]),np.array(LossTest)],axis=0)) #Test\n",
        "        plt.title('Loss Vs Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.legend(['Train', 'Validation', 'Test'], loc='upper left')\n",
        "        plt.grid('on')\n",
        "        plt.savefig(path_img_base+'/'+model_name+'/Loss_Ye_Net_'+model_name+'.eps', format='eps')\n",
        "        plt.savefig(path_img_base+'/'+model_name+'/Loss_Ye_Net_'+model_name+'.svg', format='svg')\n",
        "        plt.savefig(path_img_base+'/'+model_name+'/Loss_Ye_Net_'+model_name+'.pdf', format='pdf')\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2wqmYCBATCI"
      },
      "outputs": [],
      "source": [
        "def top_models(AccTest,AccTrain,AccValid):\n",
        "    numbers=AccTest\n",
        "    numbers_sort = sorted(enumerate(numbers), key=itemgetter(1),  reverse=True)\n",
        "    for i in range(int(len(numbers)*(0.05))): #5% total epochs\n",
        "        index, value = numbers_sort[i]\n",
        "        print(\"Test Accuracy {}, epoch:{}\\n\".format(value, index+1))\n",
        "\n",
        "    print(\"\")\n",
        "\n",
        "    numbers=AccTrain\n",
        "    numbers_sort = sorted(enumerate(numbers), key=itemgetter(1),  reverse=True)\n",
        "    for i in range(int(len(numbers)*(0.05))): #5% total epochs\n",
        "        index, value = numbers_sort[i]\n",
        "        print(\"Train Accuracy {}, epoch:{}\\n\".format(value, index+1))\n",
        "\n",
        "    print(\"\")\n",
        "\n",
        "    numbers=AccValid\n",
        "    numbers_sort = sorted(enumerate(numbers), key=itemgetter(1),  reverse=True)\n",
        "    for i in range(int(len(numbers)*(0.05))): #5% total epochs\n",
        "        index, value = numbers_sort[i]\n",
        "        print(\"Validation Accuracy {}, epoch:{}\\n\".format(value, index+1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psuBEoCGATCI"
      },
      "outputs": [],
      "source": [
        "def trainTPU(path_model, epochs, model_Name):\n",
        "    global model_name\n",
        "    start_time = tm.time()\n",
        "    model_name = model_Name\n",
        "    path_log_base = path_model+'/'+model_Name\n",
        "    if not os.path.exists(path_log_base):\n",
        "        os.makedirs(path_log_base)\n",
        "\n",
        "    with tpu_strategy.scope(): # creating the model in the TPUStrategy scope means we will train the model on the TPU\n",
        "         model = Ye_Net()\n",
        "\n",
        "    epoch_ = 1\n",
        "    for epoch in range(epochs):\n",
        "        epoch=epoch+1\n",
        "        print(\"epoch \",epoch)\n",
        "        model.fit(X_train,y_train,validation_data=(X_valid,y_valid), batch_size=128*2, epochs=epoch_, verbose=1)\n",
        "        model.save_weights(path_model+'/'+model_name+'/'+str(epoch).zfill(4)+'.hdf5', overwrite=True)\n",
        "\n",
        "    TIME = tm.time() - start_time\n",
        "    print(\"Time \"+model_name+\" = %s [seconds]\" % TIME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbrH87nlATCI"
      },
      "source": [
        "## Working with BOSSbase 1.01 WOW y PAYLOAD = 0.4bpp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRJQSSMbATCI"
      },
      "source": [
        "In the README, there is a link to download the databases we use for the work. There is BOSSbase 1.01, cover images and stego. The steganographic algorithms used in the paper are WOW and S-UNIWARD, with a payload of 0.4bpp."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qbW00EgATCI"
      },
      "source": [
        "Note: If you want to train the algorithm with S-UNIWARD 0.4 bpp, change \"PATH04_WOW1\" and  \"base_name\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LobDB00YATCI"
      },
      "source": [
        "# Different - CNN Input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stWjxUV6ATCI"
      },
      "source": [
        "To speed up the learning process and avoid issueswith GPU memory limitation, CNN optimization is performed overbatches of images rather than the complete training set. This dataset division means that the class distribution within each batch of images affects the learning process. To demonstrate the effects of stego-cover image quantity for a batch in the learning processand find the best way of feeding the images to the network, three different approaches were tested;\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ahAwfn7ATCI"
      },
      "source": [
        "-Usual(providing all the cover images, then all the stego images)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3j6rxL_ATCI"
      },
      "source": [
        "-Random(random positions of cover and stego images)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-xRPaADATCI"
      },
      "source": [
        "-order (alter-nates cover and stego images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuvLWRdkATCI"
      },
      "source": [
        "Note: Any of the nine \"CNN Input\" can be used to train your model, you can also download the databases in PGM format through a link found in the README."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4f66AluATCI"
      },
      "source": [
        "## [1] Train image distribution \"Random\", and Validation image distribution \"Usual\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1lRYZlBATCI"
      },
      "outputs": [],
      "source": [
        "n=256\n",
        "def load_images(path_pattern):\n",
        "    files=glob.glob(path_pattern)\n",
        "    X=[]\n",
        "    for f in files:\n",
        "        I = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
        "        patches = view_as_blocks(I, (n, n))\n",
        "        for i in range(patches.shape[0]):\n",
        "            for j in range(patches.shape[1]):\n",
        "                X.append( [ patches[i,j] ] )\n",
        "    X=numpy.array(X)\n",
        "    return X\n",
        "\n",
        "\n",
        "#Train Images\n",
        "Xc = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/cover/*.pgm')\n",
        "Xs = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/stego/*.pgm')\n",
        "#Validation Images\n",
        "Yc = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/cover/*.pgm')\n",
        "Ys = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/stego/*.pgm')\n",
        "\n",
        "X = (numpy.vstack((Xc, Xs)))\n",
        "Y = (numpy.vstack((Yc, Ys)))\n",
        "\n",
        "\n",
        "Xt = (numpy.hstack(([0]*len(Xc), [1]*len(Xs))))\n",
        "Yt = (numpy.hstack(([0]*len(Yc), [1]*len(Ys))))\n",
        "\n",
        "\n",
        "Xt = np_utils.to_categorical(Xt, 2)\n",
        "Yt = np_utils.to_categorical(Yt, 2)\n",
        "\n",
        "\n",
        "####random train\n",
        "idx=np.arange(len(X))\n",
        "random.shuffle(idx)\n",
        "X=X[idx]\n",
        "Xt=Xt[idx]\n",
        "\n",
        "X=np.rollaxis(X,1,4)  #channel axis shifted to last axis\n",
        "Y=np.rollaxis(Y,1,4)  #channel axis shifted to last axis\n",
        "\n",
        "\n",
        "X_train=X\n",
        "y_train=Xt\n",
        "X_valid=Y\n",
        "y_valid=Yt\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_valid.shape)\n",
        "print(y_valid.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y00n-WhJATCJ"
      },
      "source": [
        "## [2] Train image distribution \"Random\", and Validation image distribution \"Random\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUPcmpz4ATCJ"
      },
      "outputs": [],
      "source": [
        "n=256\n",
        "def load_images(path_pattern):\n",
        "    files=glob.glob(path_pattern)\n",
        "    X=[]\n",
        "    for f in files:\n",
        "        I = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
        "        patches = view_as_blocks(I, (n, n))\n",
        "        for i in range(patches.shape[0]):\n",
        "            for j in range(patches.shape[1]):\n",
        "                X.append( [ patches[i,j] ] )\n",
        "    X=numpy.array(X)\n",
        "    return X\n",
        "\n",
        "\n",
        "#Train Images\n",
        "Xc = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/cover/*.pgm')\n",
        "Xs = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/stego/*.pgm')\n",
        "#Validation Images\n",
        "Yc = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/cover/*.pgm')\n",
        "Ys = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/stego/*.pgm')\n",
        "\n",
        "\n",
        "X = (numpy.vstack((Xc, Xs)))\n",
        "Y = (numpy.vstack((Yc, Ys)))\n",
        "\n",
        "\n",
        "Xt = (numpy.hstack(([0]*len(Xc), [1]*len(Xs))))\n",
        "Yt = (numpy.hstack(([0]*len(Yc), [1]*len(Ys))))\n",
        "\n",
        "\n",
        "Xt = np_utils.to_categorical(Xt, 2)\n",
        "Yt = np_utils.to_categorical(Yt, 2)\n",
        "\n",
        "\n",
        "####random train\n",
        "idx1=np.arange(len(X))\n",
        "random.shuffle(idx1)\n",
        "X=X[idx1]\n",
        "Xt=Xt[idx1]\n",
        "\n",
        "####random valid\n",
        "idx2=np.arange(len(Y))\n",
        "random.shuffle(idx2)\n",
        "Y=Y[idx2]\n",
        "Yt=Yt[idx2]\n",
        "\n",
        "\n",
        "\n",
        "X=np.rollaxis(X,1,4)  #channel axis shifted to last axis\n",
        "Y=np.rollaxis(Y,1,4)  #channel axis shifted to last axis\n",
        "\n",
        "\n",
        "X_train=X\n",
        "y_train=Xt\n",
        "X_valid=Y\n",
        "y_valid=Yt\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_valid.shape)\n",
        "print(y_valid.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMU7Fb10ATCJ"
      },
      "source": [
        "## [3] Train image distribution \"Order\", and Validation image distribution \"Order\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sX_ZNymATCJ"
      },
      "outputs": [],
      "source": [
        "n=256\n",
        "def load_images(path_pattern):\n",
        "    files=glob.glob(path_pattern)\n",
        "    data=[]\n",
        "    for f in files:\n",
        "        I = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
        "        patches = view_as_blocks(I, (n, n))\n",
        "        for i in range(patches.shape[0]):\n",
        "            for j in range(patches.shape[1]):\n",
        "                data.append( [ patches[i,j] ] )\n",
        "    data=numpy.array(data)\n",
        "    return data\n",
        "\n",
        "def CS_X(X):\n",
        "    X2 = X.copy()\n",
        "    j=0\n",
        "    k=int(len(X)/2)\n",
        "    for i in range(int(len(X)-1)):\n",
        "        if i%2 == 0: #par\n",
        "            X2[i,:,:,0] = X[j,:,:,0]\n",
        "            j=j+1\n",
        "        if i%2 == 1: #impar\n",
        "            X2[i,:,:,0] = X[k,:,:,0]\n",
        "            k=k+1\n",
        "    return X2\n",
        "\n",
        "def CS_y(y):\n",
        "    y2 = y.copy()\n",
        "    j=0\n",
        "    k=int(len(y)/2)\n",
        "    for i in range(int(len(y)-1)):\n",
        "        if i%2 == 0: #par\n",
        "            y2[i,:] = y[j,:]\n",
        "            j=j+1\n",
        "        if i%2 == 1: #impar\n",
        "            y2[i,:] = y[k,:]\n",
        "            k=k+1\n",
        "    return y2\n",
        "\n",
        "##################################################################################################################\n",
        "\n",
        "#Train Images\n",
        "Xc0 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/cover/*.pgm')\n",
        "Xs0 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/stego/*.pgm')\n",
        "#Validation Images\n",
        "Xc1 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/cover/*.pgm')\n",
        "Xs1 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/stego/*.pgm')\n",
        "\n",
        "##################################################################################################################\n",
        "\n",
        "y_train = CS_y(np_utils.to_categorical((numpy.hstack(([0]*len(Xc0), [1]*len(Xs0)))), 2))\n",
        "y_valid = CS_y(np_utils.to_categorical((numpy.hstack(([0]*len(Xc1), [1]*len(Xs1)))), 2))\n",
        "\n",
        "\n",
        "X_train = CS_X(np.rollaxis((numpy.vstack((Xc0, Xs0))),1,4))\n",
        "X_valid = CS_X(np.rollaxis((numpy.vstack((Xc1, Xs1))),1,4))\n",
        "\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_valid.shape)\n",
        "print(y_valid.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHdHV4zvATCJ"
      },
      "source": [
        " ## [4] Train image distribution \"Usual\", and Validation image distribution \"Usual\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2M81aNUNATCJ"
      },
      "outputs": [],
      "source": [
        "n=256\n",
        "def load_images(path_pattern):\n",
        "    files=glob.glob(path_pattern)\n",
        "    X=[]\n",
        "    for f in files:\n",
        "        I = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
        "        patches = view_as_blocks(I, (n, n))\n",
        "        for i in range(patches.shape[0]):\n",
        "            for j in range(patches.shape[1]):\n",
        "                X.append( [ patches[i,j] ] )\n",
        "    X=numpy.array(X)\n",
        "    return X\n",
        "\n",
        "\n",
        "#Train Images\n",
        "Xc = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/cover/*.pgm')\n",
        "Xs = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/stego/*.pgm')\n",
        "#Validation Images\n",
        "Yc = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/cover/*.pgm')\n",
        "Ys = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/stego/*.pgm')\n",
        "\n",
        "X = (numpy.vstack((Xc, Xs)))\n",
        "Y = (numpy.vstack((Yc, Ys)))\n",
        "\n",
        "\n",
        "Xt = (numpy.hstack(([0]*len(Xc), [1]*len(Xs))))\n",
        "Yt = (numpy.hstack(([0]*len(Yc), [1]*len(Ys))))\n",
        "\n",
        "\n",
        "Xt = np_utils.to_categorical(Xt, 2)\n",
        "Yt = np_utils.to_categorical(Yt, 2)\n",
        "\n",
        "\n",
        "X=np.rollaxis(X,1,4)  #channel axis shifted to last axis\n",
        "Y=np.rollaxis(Y,1,4)  #channel axis shifted to last axis\n",
        "\n",
        "\n",
        "X_train=X\n",
        "y_train=Xt\n",
        "X_valid=Y\n",
        "y_valid=Yt\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_valid.shape)\n",
        "print(y_valid.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLONGNDxATCJ"
      },
      "source": [
        " ## [5] Train image distribution \"Order\", and Validation image distribution \"Usual\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3SbB0ZBATCJ"
      },
      "outputs": [],
      "source": [
        "n=256\n",
        "def load_images(path_pattern):\n",
        "    files=glob.glob(path_pattern)\n",
        "    data=[]\n",
        "    for f in files:\n",
        "        I = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
        "        patches = view_as_blocks(I, (n, n))\n",
        "        for i in range(patches.shape[0]):\n",
        "            for j in range(patches.shape[1]):\n",
        "                data.append( [ patches[i,j] ] )\n",
        "    data=numpy.array(data)\n",
        "    return data\n",
        "\n",
        "def CS_X(X):\n",
        "    X2 = X.copy()\n",
        "    j=0\n",
        "    k=int(len(X)/2)\n",
        "    for i in range(int(len(X)-1)):\n",
        "        if i%2 == 0: #par\n",
        "            X2[i,:,:,0] = X[j,:,:,0]\n",
        "            j=j+1\n",
        "        if i%2 == 1: #impar\n",
        "            X2[i,:,:,0] = X[k,:,:,0]\n",
        "            k=k+1\n",
        "    return X2\n",
        "\n",
        "def CS_y(y):\n",
        "    y2 = y.copy()\n",
        "    j=0\n",
        "    k=int(len(y)/2)\n",
        "    for i in range(int(len(y)-1)):\n",
        "        if i%2 == 0: #par\n",
        "            y2[i,:] = y[j,:]\n",
        "            j=j+1\n",
        "        if i%2 == 1: #impar\n",
        "            y2[i,:] = y[k,:]\n",
        "            k=k+1\n",
        "    return y2\n",
        "\n",
        "##################################################################################################################\n",
        "\n",
        "#Train Images\n",
        "Xc0 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/cover/*.pgm')\n",
        "Xs0 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/stego/*.pgm')\n",
        "#Validation Images\n",
        "Xc1 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/cover/*.pgm')\n",
        "Xs1 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/stego/*.pgm')\n",
        "\n",
        "##################################################################################################################\n",
        "\n",
        "y_train = CS_y(np_utils.to_categorical((numpy.hstack(([0]*len(Xc0), [1]*len(Xs0)))), 2))\n",
        "y_valid = np_utils.to_categorical((numpy.hstack(([0]*len(Xc1), [1]*len(Xs1)))), 2)\n",
        "\n",
        "X_train = CS_X(np.rollaxis((numpy.vstack((Xc0, Xs0))),1,4))\n",
        "X_valid = np.rollaxis((numpy.vstack((Xc1, Xs1))),1,4)\n",
        "\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_valid.shape)\n",
        "print(y_valid.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCpD3PxfATCJ"
      },
      "source": [
        " ## [6] Train image distribution \"Order\", and Validation image distribution \"Random\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0JKPuQxwATCJ"
      },
      "outputs": [],
      "source": [
        "n=256\n",
        "def load_images(path_pattern):\n",
        "    files=glob.glob(path_pattern)\n",
        "    data=[]\n",
        "    for f in files:\n",
        "        I = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
        "        patches = view_as_blocks(I, (n, n))\n",
        "        for i in range(patches.shape[0]):\n",
        "            for j in range(patches.shape[1]):\n",
        "                data.append( [ patches[i,j] ] )\n",
        "    data=numpy.array(data)\n",
        "    return data\n",
        "\n",
        "def CS_X(X):\n",
        "    X2 = X.copy()\n",
        "    j=0\n",
        "    k=int(len(X)/2)\n",
        "    for i in range(int(len(X)-1)):\n",
        "        if i%2 == 0: #par\n",
        "            X2[i,:,:,0] = X[j,:,:,0]\n",
        "            j=j+1\n",
        "        if i%2 == 1: #impar\n",
        "            X2[i,:,:,0] = X[k,:,:,0]\n",
        "            k=k+1\n",
        "    return X2\n",
        "\n",
        "def CS_y(y):\n",
        "    y2 = y.copy()\n",
        "    j=0\n",
        "    k=int(len(y)/2)\n",
        "    for i in range(int(len(y)-1)):\n",
        "        if i%2 == 0: #par\n",
        "            y2[i,:] = y[j,:]\n",
        "            j=j+1\n",
        "        if i%2 == 1: #impar\n",
        "            y2[i,:] = y[k,:]\n",
        "            k=k+1\n",
        "    return y2\n",
        "\n",
        "##################################################################################################################\n",
        "\n",
        "#Train Images\n",
        "Xc0 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/cover/*.pgm')\n",
        "Xs0 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/stego/*.pgm')\n",
        "#Validation Images\n",
        "Yc = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/cover/*.pgm')\n",
        "Ys = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/stego/*.pgm')\n",
        "\n",
        "##################################################################################################################\n",
        "\n",
        "y_train = CS_y(np_utils.to_categorical((numpy.hstack(([0]*len(Xc0), [1]*len(Xs0)))), 2))\n",
        "X_train = CS_X(np.rollaxis((numpy.vstack((Xc0, Xs0))),1,4))\n",
        "\n",
        "Y = (numpy.vstack((Yc, Ys)))\n",
        "Z = (numpy.vstack((Zc, Zs)))\n",
        "\n",
        "Yt = (numpy.hstack(([0]*len(Yc), [1]*len(Ys))))\n",
        "\n",
        "\n",
        "Yt = np_utils.to_categorical(Yt, 2)\n",
        "\n",
        "####Random valid\n",
        "idx2=np.arange(len(Y))\n",
        "random.shuffle(idx2)\n",
        "Y=Y[idx2]\n",
        "Yt=Yt[idx2]\n",
        "\n",
        "Y=np.rollaxis(Y,1,4)  #channel axis shifted to last axis\n",
        "\n",
        "X_valid=Y\n",
        "y_valid=Yt\n",
        "\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_valid.shape)\n",
        "print(y_valid.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdM-zD6TATCK"
      },
      "source": [
        " ## [7] Train image distribution \"Random\", and Validation image distribution \"Order\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAgYyQJjATCK"
      },
      "outputs": [],
      "source": [
        "n=256\n",
        "def load_images(path_pattern):\n",
        "    files=glob.glob(path_pattern)\n",
        "    data=[]\n",
        "    for f in files:\n",
        "        I = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
        "        patches = view_as_blocks(I, (n, n))\n",
        "        for i in range(patches.shape[0]):\n",
        "            for j in range(patches.shape[1]):\n",
        "                data.append( [ patches[i,j] ] )\n",
        "    data=numpy.array(data)\n",
        "    return data\n",
        "\n",
        "def CS_X(X):\n",
        "    X2 = X.copy()\n",
        "    j=0\n",
        "    k=int(len(X)/2)\n",
        "    for i in range(int(len(X)-1)):\n",
        "        if i%2 == 0: #par\n",
        "            X2[i,:,:,0] = X[j,:,:,0]\n",
        "            j=j+1\n",
        "        if i%2 == 1: #impar\n",
        "            X2[i,:,:,0] = X[k,:,:,0]\n",
        "            k=k+1\n",
        "    return X2\n",
        "\n",
        "def CS_y(y):\n",
        "    y2 = y.copy()\n",
        "    j=0\n",
        "    k=int(len(y)/2)\n",
        "    for i in range(int(len(y)-1)):\n",
        "        if i%2 == 0: #par\n",
        "            y2[i,:] = y[j,:]\n",
        "            j=j+1\n",
        "        if i%2 == 1: #impar\n",
        "            y2[i,:] = y[k,:]\n",
        "            k=k+1\n",
        "    return y2\n",
        "\n",
        "##################################################################################################################\n",
        "\n",
        "#Train Images\n",
        "Xc = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/cover/*.pgm')\n",
        "Xs = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/stego/*.pgm')\n",
        "#Validation Images\n",
        "Xc1 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/cover/*.pgm')\n",
        "Xs1 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/stego/*.pgm')\n",
        "\n",
        "\n",
        "##################################################################################################################\n",
        "\n",
        "y_valid = np_utils.to_categorical((numpy.hstack(([0]*len(Xc1), [1]*len(Xs1)))), 2)\n",
        "X_valid = np.rollaxis((numpy.vstack((Xc1, Xs1))),1,4)\n",
        "\n",
        "\n",
        "X = (numpy.vstack((Xc, Xs)))\n",
        "Xt = (numpy.hstack(([0]*len(Xc), [1]*len(Xs))))\n",
        "Xt = np_utils.to_categorical(Xt, 2)\n",
        "####Random train\n",
        "idx1=np.arange(len(X))\n",
        "random.shuffle(idx1)\n",
        "X=X[idx1]\n",
        "Xt=Xt[idx1]\n",
        "X=np.rollaxis(X,1,4)  #channel axis shifted to last axis\n",
        "X_train=X\n",
        "y_train=Xt\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_valid.shape)\n",
        "print(y_valid.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7t7jf35eATCK"
      },
      "source": [
        " ## [8] Train image distribution \"Usual\", and Validation image distribution \"Random\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEPAZc1uATCK"
      },
      "outputs": [],
      "source": [
        "n=256\n",
        "def load_images(path_pattern):\n",
        "    files=glob.glob(path_pattern)\n",
        "    X=[]\n",
        "    for f in files:\n",
        "        I = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
        "        patches = view_as_blocks(I, (n, n))\n",
        "        for i in range(patches.shape[0]):\n",
        "            for j in range(patches.shape[1]):\n",
        "                X.append( [ patches[i,j] ] )\n",
        "    X=numpy.array(X)\n",
        "    return X\n",
        "\n",
        "#Train Images\n",
        "Xc = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/cover/*.pgm')\n",
        "Xs = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/stego/*.pgm')\n",
        "#Validation Images\n",
        "Yc = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/cover/*.pgm')\n",
        "Ys = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/stego/*.pgm')\n",
        "\n",
        "\n",
        "X = (numpy.vstack((Xc, Xs)))\n",
        "Y = (numpy.vstack((Yc, Ys)))\n",
        "\n",
        "\n",
        "Xt = (numpy.hstack(([0]*len(Xc), [1]*len(Xs))))\n",
        "Yt = (numpy.hstack(([0]*len(Yc), [1]*len(Ys))))\n",
        "\n",
        "\n",
        "Xt = np_utils.to_categorical(Xt, 2)\n",
        "Yt = np_utils.to_categorical(Yt, 2)\n",
        "\n",
        "\n",
        "####random valid\n",
        "idx2=np.arange(len(Y))\n",
        "random.shuffle(idx2)\n",
        "Y=Y[idx2]\n",
        "Yt=Yt[idx2]\n",
        "\n",
        "\n",
        "X=np.rollaxis(X,1,4)  #channel axis shifted to last axis\n",
        "Y=np.rollaxis(Y,1,4)  #channel axis shifted to last axis\n",
        "\n",
        "\n",
        "X_train=X\n",
        "y_train=Xt\n",
        "X_valid=Y\n",
        "y_valid=Yt\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_valid.shape)\n",
        "print(y_valid.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Yy7Nml4ATCK"
      },
      "source": [
        " ## [9] Train image distribution \"Usual\", and Validation image distribution \"Order\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41h5RgokATCK"
      },
      "outputs": [],
      "source": [
        "n=256\n",
        "def load_images(path_pattern):\n",
        "    files=glob.glob(path_pattern)\n",
        "    data=[]\n",
        "    for f in files:\n",
        "        I = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
        "        patches = view_as_blocks(I, (n, n))\n",
        "        for i in range(patches.shape[0]):\n",
        "            for j in range(patches.shape[1]):\n",
        "                data.append( [ patches[i,j] ] )\n",
        "    data=numpy.array(data)\n",
        "    return data\n",
        "\n",
        "def CS_X(X):\n",
        "    X2 = X.copy()\n",
        "    j=0\n",
        "    k=int(len(X)/2)\n",
        "    for i in range(int(len(X)-1)):\n",
        "        if i%2 == 0: #par\n",
        "            X2[i,:,:,0] = X[j,:,:,0]\n",
        "            j=j+1\n",
        "        if i%2 == 1: #impar\n",
        "            X2[i,:,:,0] = X[k,:,:,0]\n",
        "            k=k+1\n",
        "    return X2\n",
        "\n",
        "def CS_y(y):\n",
        "    y2 = y.copy()\n",
        "    j=0\n",
        "    k=int(len(y)/2)\n",
        "    for i in range(int(len(y)-1)):\n",
        "        if i%2 == 0: #par\n",
        "            y2[i,:] = y[j,:]\n",
        "            j=j+1\n",
        "        if i%2 == 1: #impar\n",
        "            y2[i,:] = y[k,:]\n",
        "            k=k+1\n",
        "    return y2\n",
        "\n",
        "##################################################################################################################\n",
        "\n",
        "#Train Images\n",
        "Xc0 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/cover/*.pgm')\n",
        "Xs0 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/stego/*.pgm')\n",
        "#Validation Images\n",
        "Xc1 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/cover/*.pgm')\n",
        "Xs1 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/stego/*.pgm')\n",
        "\n",
        "##################################################################################################################\n",
        "\n",
        "y_train = np_utils.to_categorical((numpy.hstack(([0]*len(Xc0), [1]*len(Xs0)))), 2)\n",
        "y_valid = CS_y(np_utils.to_categorical((numpy.hstack(([0]*len(Xc1), [1]*len(Xs1)))), 2))\n",
        "\n",
        "X_train = np.rollaxis((numpy.vstack((Xc0, Xs0))),1,4)\n",
        "X_valid = CS_y(np.rollaxis((numpy.vstack((Xc1, Xs1))),1,4))\n",
        "\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_valid.shape)\n",
        "print(y_valid.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kTiRl-7ATCK"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scRlrMzYATCK"
      },
      "outputs": [],
      "source": [
        "path_model = \"./WOW/logs\"\n",
        "path_img_base = \"./Image/WOW/images\"\n",
        "\n",
        "model_Name = \"Ye_Net...\"\n",
        "\n",
        "trainTPU(path_model=path_model, epochs=150, model_Name = \"Ye_Net...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSZRObHYATCL"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wv97KymDATCL"
      },
      "outputs": [],
      "source": [
        "Final_Results_Test(path_model+\"/\"+model_Name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzzuUT7aATCL"
      },
      "source": [
        "## Valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rcl1Jz7oATCL"
      },
      "outputs": [],
      "source": [
        "Final_Results_Valid(path_model+\"/\"+model_Name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skCqY-XhATCL"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oe1fOaUhATCL"
      },
      "outputs": [],
      "source": [
        "Final_Results_Train(path_model+\"/\"+model_Name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-ajpiA0ATCL"
      },
      "source": [
        "## graphics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leZiE2uaATCL"
      },
      "outputs": [],
      "source": [
        "graphics(AccTest, AccTrain, AccValid, LossTest, LossTrain, LossValid, model_Name, path_img_base)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eP2TPYVIATCL"
      },
      "source": [
        "Note: If you want to train the algorithm with S-UNIWARD 0.4 bpp, change \"PATH04_WOW1\" and  \"base_name\"."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}